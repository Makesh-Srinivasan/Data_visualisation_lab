model_1 <- lm(circumference~.,data=data_2d)
model_1
model_2 <- lm(age~.,data=data_2d)
model_2
data_2d <- subset(data, select = -c(Tree))
model_1 <- lm(circumference~.,data=data_2d)
model_1
# Model 1
summary(model_1)
# Model 2
summary(model_2)
# Model 2
summary(model_2)
# head:
head(data, 5)
# tribble
as.tibble(data)
# What type of data are each of the columns?
str(data)
nlevels(data$Tree)
# Model 1
summary(model_1)
anova(model_1)
# Model 2
summary(model_2)
anova(model_2)
cor(data$age, data$circumference)
# The p value is given above already. But I have printed it here again anyway. NOTE: the p value will be the same for both model 1 and 2 (question 5)
annova(model_1)
# The p value is given above already. But I have printed it here again anyway. NOTE: the p value will be the same for both model 1 and 2 (question 5)
anova(model_1)
cor(data$age, data$circumference, method="pearson")
cor.test(data$age, data$circumference, method="pearson")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
g <- ggplot(data, aes(Wr.Hnd, NW.Hnd)) + geom_point()
library(ggplot2)
g <- ggplot(data, aes(Wr.Hnd, NW.Hnd)) + geom_point()
g
library(ggplot2)
g <- ggplot(data, aes(age, circumference)) + geom_point()
g
library(ggplot2)
g <- ggplot(data, aes(age, circumference)) + geom_point() + geom_line()
g
library(ggplot2)
g <- ggplot(data, aes(age, circumference)) + geom_point() + geom_smooth()
g
library(ggplot2)
g <- ggplot(data, aes(age, circumference)) + geom_point() + geom_smooth(method="lm", se=F) + labs(subtitle="Age vs circumference", y="Age", x="Circumference", title="Linear fit on the data points", caption="Source: data")
g
knitr::opts_chunk$set(echo = TRUE)
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
mtcars.pca <- prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
summary(mtcars.pca)
str(mtcars.pca)
library(devtools)
install.packages(devtools)
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(MASS)
library(dplyr)
library(ggplot2)
library(devtools)
install_github("vqv/ggbiplot")
knitr::opts_chunk$set(echo = TRUE)
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
library(tidyverse)
library(MASS)
library(dplyr)
library(ggplot2)
library(devtools)
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
library(tidyverse)
library(MASS)
library(dplyr)
library(ggplot2)
library(devtools)
library(astsa, quietly=TRUE, warn.conflicts=FALSE)
library(tidyverse)
library(MASS)
library(dplyr)
library(ggplot2)
library(devtools)
library.install(astsa)
install.packages("astsa")
library(tidyverse)
library(MASS)
library(dplyr)
library(ggplot2)
library(devtools)
library(astsa, quietly=TRUE, warn.conflicts=FALSE)
require(knitr)
library(tidyverse)
library(MASS)
library(dplyr)
library(ggplot2)
library(devtools)
library(astsa, quietly=TRUE, warn.conflicts=FALSE)
require(knitr)
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
#Age of Death of Successive Kings of England
#starting with William the Conqueror
#kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
#kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.data",skip=3)
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- read_csv("kings.csv")
# Read 42 items
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- read_csv("kings.csv")
# Read 42 items
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- read_csv("kings.csv")
# Read 42 items
kings
kingstimeseries <- ts(kings)
kingstimeseries
#Time Series:
births <- scan("http://robjhyndman.com/tsdldata/data/nybirths.dat")
kings
kingstimeseries <- ts(kings)
kingstimeseries
#Time Series:
births <- read_csv("births.csv")
#Read 168 items
birthstimeseries <- ts(births, frequency=12, start=c(1946,1))
birthstimeseries
souvenir <- scan("http://robjhyndman.com/tsdldata/data/fancy.dat")
kings
kingstimeseries <- ts(kings)
kingstimeseries
#Time Series:
births <- read_csv("births.csv")
#Read 168 items
birthstimeseries <- ts(births, frequency=12, start=c(1946,1))
birthstimeseries
souvenir <- read_csv("souvenier.csv")
souvenirtimeseries <- ts(souvenir, frequency=12, start=c(1987,1))
souvenirtimeseries
plot.ts(kingstimeseries)
plot.ts(birthstimeseries)
plot.ts(souvenirtimeseries)
logsouvenirtimeseries <- log(souvenirtimeseries)
plot.ts(logsouvenirtimeseries)
#SMA - Simple Moving Average
library("TTR")
kingstimeseriesSMA3 <- SMA(kingstimeseries,n=3)
plot.ts(kingstimeseriesSMA3)
birthstimeseriescomponents <- decompose(birthstimeseries)
birthstimeseriescomponents$seasonal # get the estimated values of the seasonal component
plot(birthstimeseriescomponents)
#Forecast using Exponential smoothing
rain <- read_csv("rains.csv")
rainseries <- ts(rain,start=c(1813))
plot.ts(rainseries)
rainseriesforecasts <- HoltWinters(rainseries, beta=FALSE, gamma=FALSE)
rainseriesforecasts
rainseriesforecasts$fitted
plot(rainseriesforecasts)
rainseriesforecasts$SSE
HoltWinters(rainseries, beta=FALSE, gamma=FALSE, l.start=23.56)
#Forecast
print(paste("Mean of circumference: ", mean(data$circumference)))
mtcars.pca <- prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
summary(mtcars.pca)
str(mtcars.pca)
library(devtools)
install_github("vqv/ggbiplot")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(MASS)
library(dplyr)
library(ggplot2)
library(devtools)
library(astsa, quietly=TRUE, warn.conflicts=FALSE)
require(knitr)
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- read_csv("kings.csv")
# Read 42 items
kings
kingstimeseries <- ts(kings)
kingstimeseries
#Time Series:
births <- read_csv("births.csv")
#Read 168 items
birthstimeseries <- ts(births, frequency=12, start=c(1946,1))
birthstimeseries
souvenir <- read_csv("souvenier.csv")
souvenirtimeseries <- ts(souvenir, frequency=12, start=c(1987,1))
souvenirtimeseries
plot.ts(kingstimeseries)
plot.ts(birthstimeseries)
plot.ts(souvenirtimeseries)
logsouvenirtimeseries <- log(souvenirtimeseries)
plot.ts(logsouvenirtimeseries)
#SMA - Simple Moving Average
library("TTR")
kingstimeseriesSMA3 <- SMA(kingstimeseries,n=3)
plot.ts(kingstimeseriesSMA3)
birthstimeseriescomponents <- decompose(birthstimeseries)
birthstimeseriescomponents$seasonal # get the estimated values of the seasonal component
plot(birthstimeseriescomponents)
#Forecast using Exponential smoothing
rain <- read_csv("rains.csv")
rainseries <- ts(rain,start=c(1813))
plot.ts(rainseries)
rainseriesforecasts <- HoltWinters(rainseries, beta=FALSE, gamma=FALSE)
rainseriesforecasts
rainseriesforecasts$fitted
plot(rainseriesforecasts)
rainseriesforecasts$SSE
HoltWinters(rainseries, beta=FALSE, gamma=FALSE, l.start=23.56)
#Forecast
mtcars.pca <- prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
summary(mtcars.pca)
str(mtcars.pca)
library(devtools)
library(ggbiplot)
remotes::install_github('vqv/ggbiplot')
knitr::opts_chunk$set(echo = TRUE)
library('ggbiplot')
install.packages('ggbiplot')
library(tidyverse)
library(MASS)
library(dplyr)
library(ggplot2)
library(devtools)
library(astsa, quietly=TRUE, warn.conflicts=FALSE)
require(knitr)
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- read_csv("kings.csv")
# Read 42 items
kings
kingstimeseries <- ts(kings)
kingstimeseries
#Time Series:
births <- read_csv("births.csv")
#Read 168 items
birthstimeseries <- ts(births, frequency=12, start=c(1946,1))
birthstimeseries
souvenir <- read_csv("souvenier.csv")
souvenirtimeseries <- ts(souvenir, frequency=12, start=c(1987,1))
souvenirtimeseries
plot.ts(kingstimeseries)
plot.ts(birthstimeseries)
plot.ts(souvenirtimeseries)
logsouvenirtimeseries <- log(souvenirtimeseries)
plot.ts(logsouvenirtimeseries)
#SMA - Simple Moving Average
library("TTR")
kingstimeseriesSMA3 <- SMA(kingstimeseries,n=3)
plot.ts(kingstimeseriesSMA3)
birthstimeseriescomponents <- decompose(birthstimeseries)
birthstimeseriescomponents$seasonal # get the estimated values of the seasonal component
plot(birthstimeseriescomponents)
#Forecast using Exponential smoothing
rain <- read_csv("rains.csv")
rainseries <- ts(rain,start=c(1813))
plot.ts(rainseries)
rainseriesforecasts <- HoltWinters(rainseries, beta=FALSE, gamma=FALSE)
rainseriesforecasts
rainseriesforecasts$fitted
plot(rainseriesforecasts)
rainseriesforecasts$SSE
HoltWinters(rainseries, beta=FALSE, gamma=FALSE, l.start=23.56)
#Forecast
install.packages('ggbiplot')
mtcars.pca <- prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
summary(mtcars.pca)
str(mtcars.pca)
library(devtools)
library(ggbiplot)
library(devtools)
install_github("vqv/ggbiplot")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(MASS)
library(dplyr)
library(ggplot2)
library(devtools)
library(astsa, quietly=TRUE, warn.conflicts=FALSE)
require(knitr)
#Age of Death of Successive Kings of England
#starting with William the Conqueror
kings <- read_csv("kings.csv")
# Read 42 items
kings
kingstimeseries <- ts(kings)
kingstimeseries
#Time Series:
births <- read_csv("births.csv")
#Read 168 items
birthstimeseries <- ts(births, frequency=12, start=c(1946,1))
birthstimeseries
souvenir <- read_csv("souvenier.csv")
souvenirtimeseries <- ts(souvenir, frequency=12, start=c(1987,1))
souvenirtimeseries
plot.ts(kingstimeseries)
plot.ts(birthstimeseries)
plot.ts(souvenirtimeseries)
logsouvenirtimeseries <- log(souvenirtimeseries)
plot.ts(logsouvenirtimeseries)
#SMA - Simple Moving Average
library("TTR")
kingstimeseriesSMA3 <- SMA(kingstimeseries,n=3)
plot.ts(kingstimeseriesSMA3)
birthstimeseriescomponents <- decompose(birthstimeseries)
birthstimeseriescomponents$seasonal # get the estimated values of the seasonal component
plot(birthstimeseriescomponents)
#Forecast using Exponential smoothing
rain <- read_csv("rains.csv")
rainseries <- ts(rain,start=c(1813))
plot.ts(rainseries)
rainseriesforecasts <- HoltWinters(rainseries, beta=FALSE, gamma=FALSE)
rainseriesforecasts
rainseriesforecasts$fitted
plot(rainseriesforecasts)
rainseriesforecasts$SSE
HoltWinters(rainseries, beta=FALSE, gamma=FALSE, l.start=23.56)
#Forecast
mtcars.pca <- prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
summary(mtcars.pca)
str(mtcars.pca)
library(devtools)
screeplot(mtcars.pca, type = "l", npcs = 15, main = "Screeplot of the first 10 PCs")
cumpro <- cumsum(mtcars.pca$sdev^2 / sum(mtcars.pca$sdev^2))
plot(cumpro[0:15], xlab = "PC #", ylab = "Amount of explained variance", main = "Cumulative variance plot")
plot(mtcars.pca$x[,1],mtcars.pca$x[,2], xlab="PC1 (44.3%)", ylab = "PC2 (19%)", main = "PC1 / PC2 - plot")
data_2d <- subset(data, select = -c(Tree))
require(MASS)
# Load data
data(iris)
head(iris, 3)
r <- lda(formula = Species ~ .,
data = iris,
prior = c(1,1,1)/3)
r$prior
r$counts
r$means
r$scaling
r$svd
prop = r$svd^2/sum(r$svd^2)
prop
r2 <- lda(formula = Species ~ .,
data = iris,
prior = c(1,1,1)/3,
CV = TRUE)
head(r2$class)
head(r2$posterior, 3)
train <- sample(1:150, 75)
r3 <- lda(Species ~ ., # training model
iris,
prior = c(1,1,1)/3,
subset = train)
plda = predict(object = r, # predictions
newdata = iris[-train, ])
head(plda$class) # classification result
head(plda$posterior, 3)
head(plda$x, 3) # LD projections
plda_plot <- cbind(train, predict(r3)$x)
ggplot(plda_plot, aes(r2, r3)) + geom_point(aes(color = Species))
require(MASS)
# Load data
data(iris)
head(iris, 3)
r <- lda(formula = Species ~ .,
data = iris,
prior = c(1,1,1)/3)
r$prior
r$counts
r$means
r$scaling
r$svd
prop = r$svd^2/sum(r$svd^2)
prop
r2 <- lda(formula = Species ~ .,
data = iris,
prior = c(1,1,1)/3,
CV = TRUE)
head(r2$class)
head(r2$posterior, 3)
train <- sample(1:150, 75)
r3 <- lda(Species ~ ., # training model
iris,
prior = c(1,1,1)/3,
subset = train)
plda = predict(object = r, # predictions
newdata = iris[-train, ])
head(plda$class) # classification result
head(plda$posterior, 3)
head(plda$x, 3) # LD projections
plda_plot <- cbind(train, predict(r3)$x)
data <- read_csv("data.csv")
mtcars.pca <- prcomp(data[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
data <- read_csv("data.csv")
str(data)
data <- read_csv("data.csv")
mtcars.pca <- prcomp(data[,c(1, 3:32)], center = TRUE,scale. = TRUE)
summary(mtcars.pca)
str(mtcars.pca)
library(devtools)
screeplot(mtcars.pca, type = "l", npcs = 15, main = "Screeplot of the first 10 PCs")
cumpro <- cumsum(mtcars.pca$sdev^2 / sum(mtcars.pca$sdev^2))
plot(cumpro[0:15], xlab = "PC #", ylab = "Amount of explained variance", main = "Cumulative variance plot")
plot(mtcars.pca$x[,1],mtcars.pca$x[,2], xlab="PC1 (44.3%)", ylab = "PC2 (19%)", main = "PC1 / PC2 - plot")
knitr::opts_chunk$set(echo = TRUE)
wdbc <- read.csv("data.csv", header = F)
features <- c("radius", "texture", "perimeter", "area", "smoothness", "compactness", "concavity", "concave_points", "symmetry", "fractal_dimension")
names(wdbc) <- c("id", "diagnosis", paste0(features,"_mean"), paste0(features,"_se"), paste0(features,"_worst"))
wdbc <- read.csv("wdbc.csv", header = F)
wdbc <- read.csv("data", header = F)
wdbc.pr <- prcomp(wdbc[c(3:32)], center = TRUE, scale = TRUE)
wdbc <- read.csv("data.csv", header = F)
features <- c("radius", "texture", "perimeter", "area", "smoothness", "compactness", "concavity", "concave_points", "symmetry", "fractal_dimension")
names(wdbc) <- c("id", "diagnosis", paste0(features,"_mean"), paste0(features,"_se"), paste0(features,"_worst"))
wdbc.pr <- prcomp(wdbc[c(3:32)], center = TRUE, scale = TRUE)
wdbc <- read.csv("wdbc", header = F)
wdbc <- read.csv("wdbc.csv", header = F)
features <- c("radius", "texture", "perimeter", "area", "smoothness", "compactness", "concavity", "concave_points", "symmetry", "fractal_dimension")
names(wdbc) <- c("id", "diagnosis", paste0(features,"_mean"), paste0(features,"_se"), paste0(features,"_worst"))
wdbc.pr <- prcomp(wdbc[c(3:32)], center = TRUE, scale = TRUE)
summary(wdbc.pr)
screeplot(wdbc.pr, type = "l", npcs = 15, main = "Screeplot of the first 10 PCs")
abline(h = 1, col="red", lty=5)
legend("topright", legend=c("Eigenvalue = 1"),
col=c("red"), lty=5, cex=0.6)
cumpro <- cumsum(wdbc.pr$sdev^2 / sum(wdbc.pr$sdev^2))
plot(cumpro[0:15], xlab = "PC #", ylab = "Amount of explained variance", main = "Cumulative variance plot")
abline(v = 6, col="blue", lty=5)
abline(h = 0.88759, col="blue", lty=5)
legend("topleft", legend=c("Cut-off @ PC6"),
col=c("blue"), lty=5, cex=0.6)
screeplot(wdbc.pr, type = "l", npcs = 15, main = "Screeplot of the first 10 PCs")
abline(h = 1, col="red", lty=5)
legend("topright", legend=c("Eigenvalue = 1"),
col=c("red"), lty=5, cex=0.6)
cumpro <- cumsum(wdbc.pr$sdev^2 / sum(wdbc.pr$sdev^2))
plot(cumpro[0:15], xlab = "PC #", ylab = "Amount of explained variance", main = "Cumulative variance plot")
abline(v = 6, col="blue", lty=5)
abline(h = 0.88759, col="blue", lty=5)
legend("topleft", legend=c("Cut-off @ PC6"),
col=c("blue"), lty=5, cex=0.6)
plot(wdbc.pr$x[,1],wdbc.pr$x[,2], xlab="PC1 (44.3%)", ylab = "PC2 (19%)", main = "PC1 / PC2 - plot")
library("factoextra")
install.packages(factoextra)
library("factoextra")
install.packages(factoextra)
install.packages("factoextra")
install.packages(factoextra)
library("factoextra")
fviz_pca_ind(wdbc.pr, geom.ind = "point", pointshape = 21,
pointsize = 2,
fill.ind = wdbc$diagnosis,
col.ind = "black",
palette = "jco",
addEllipses = TRUE,
label = "var",
col.var = "black",
repel = TRUE,
legend.title = "Diagnosis") +
ggtitle("2D PCA-plot from 30 feature dataset") +
theme(plot.title = element_text(hjust = 0.5))
wdbc <- read.csv("wdbc.csv", header = F)
features <- c("radius", "texture", "perimeter", "area", "smoothness", "compactness", "concavity", "concave_points", "symmetry", "fractal_dimension")
names(wdbc) <- c("id", "diagnosis", paste0(features,"_mean"), paste0(features,"_se"), paste0(features,"_worst"))
wdbc.data <- as.matrix(wdbc[,c(3:32)])
row.names(wdbc.data) <- wdbc$id
wdbc_raw <- cbind(wdbc.data, as.numeric(wdbc$diagnosis)-1)
colnames(wdbc_raw)[31] <- "diagnosis"
smp_size_raw <- floor(0.75 * nrow(wdbc_raw))
train_ind_raw <- sample(nrow(wdbc_raw), size = smp_size_raw)
train_raw.df <- as.data.frame(wdbc_raw[train_ind_raw, ])
test_raw.df <- as.data.frame(wdbc_raw[-train_ind_raw, ])
f <- paste(names(train_raw.df)[31], "~", paste(names(train_raw.df)[-31], collapse=" + "))
wdbc_raw.lda <- lda(as.formula(paste(f)), data = train_raw.df)
wdbc_raw.lda.predict <- predict(wdbc_raw.lda, newdata = test_raw.df)
wdbc <- read.csv("wdbc.csv", header = F)
features <- c("radius", "texture", "perimeter", "area", "smoothness", "compactness", "concavity", "concave_points", "symmetry", "fractal_dimension")
names(wdbc) <- c("id", "diagnosis", paste0(features,"_mean"), paste0(features,"_se"), paste0(features,"_worst"))
wdbc.data <- as.matrix(wdbc[,c(3:32)])
row.names(wdbc.data) <- wdbc$id
wdbc_raw <- cbind(wdbc.data, as.numeric(wdbc$diagnosis)-1)
colnames(wdbc_raw)[31] <- "diagnosis"
smp_size_raw <- floor(0.75 * nrow(wdbc_raw))
train_ind_raw <- sample(nrow(wdbc_raw), size = smp_size_raw)
train_raw.df <- as.data.frame(wdbc_raw[train_ind_raw, ])
test_raw.df <- as.data.frame(wdbc_raw[-train_ind_raw, ])
f <- paste(names(train_raw.df)[31], "~", paste(names(train_raw.df)[-31], collapse=" + "))
wdbc_raw.lda <- lda(as.formula(paste(f)), data = train_raw.df)
